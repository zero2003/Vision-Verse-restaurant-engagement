We used selenium for web scraping because it fully renders web pages, executes JavaScript, and interacts with web elements like a human would. The Menulog website uses lazy loading for images. This means the images are only loaded when they come into the user's viewport (triggered by JavaScript as the user scrolls). Selenium can handle this by opening the link in a browser (in this case, selenium is using chromedriver as the browser), scrolling the page, and waiting for the images to load (look at the script and see how "ActionChains" is used to scroll through the page), something that BeautifulSoup alone cannot do.